{"container_type": "Author", "filled": ["basics", "publications", "indices", "counts"], "scholar_id": "m2M6b58AAAAJ", "source": "AUTHOR_PROFILE_PAGE", "name": "Zhuofan Xia", "url_picture": "https://scholar.googleusercontent.com/citations?view_op=view_photo&user=m2M6b58AAAAJ&citpid=9", "affiliation": "PhD candidate, Department of Automation, Tsinghua University", "organization": 15442380624744264287, "interests": ["Efficient Deep Learning", "Computer Vision", "Multimodal Learning"], "email_domain": "@mails.tsinghua.edu.cn", "homepage": "https://www.zhuofanxia.xyz/", "citedby": 1486, "publications": {"m2M6b58AAAAJ:u-x6o8ySG0sC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Vision Transformer with Deformable Attention", "pub_year": "2022"}, "filled": false, "author_pub_id": "m2M6b58AAAAJ:u-x6o8ySG0sC", "num_citations": 664, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=11231231375435598889", "cites_id": ["11231231375435598889"]}, "m2M6b58AAAAJ:u5HHmVD_uO8C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "3D Object Detection with Pointformer", "pub_year": "2021"}, "filled": false, "author_pub_id": "m2M6b58AAAAJ:u5HHmVD_uO8C", "num_citations": 456, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=586972148582341814", "cites_id": ["586972148582341814"]}, "m2M6b58AAAAJ:qjMakFHDy7sC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Adaptive Rotated Convolution for Rotated Object Detection", "pub_year": "2023"}, "filled": false, "author_pub_id": "m2M6b58AAAAJ:qjMakFHDy7sC", "num_citations": 101, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=972330593407502807", "cites_id": ["972330593407502807"]}, "m2M6b58AAAAJ:Tyk-4Ss8FVUC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Agent attention: On the integration of softmax and linear attention", "pub_year": "2024"}, "filled": false, "author_pub_id": "m2M6b58AAAAJ:Tyk-4Ss8FVUC", "num_citations": 80, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=9211883786541196964", "cites_id": ["9211883786541196964"]}, "m2M6b58AAAAJ:UeHWp8X0CEIC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Slide-transformer: Hierarchical vision transformer with local self-attention", "pub_year": "2023"}, "filled": false, "author_pub_id": "m2M6b58AAAAJ:UeHWp8X0CEIC", "num_citations": 67, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=16785214338933446444", "cites_id": ["16785214338933446444"]}, "m2M6b58AAAAJ:Y0pCki6q_DkC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "GSVA: Generalized Segmentation via Multimodal Large Language Models", "pub_year": "2024"}, "filled": false, "author_pub_id": "m2M6b58AAAAJ:Y0pCki6q_DkC", "num_citations": 40, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=3323355051068836966", "cites_id": ["3323355051068836966"]}, "m2M6b58AAAAJ:W7OEmFMy1HYC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Demystify Mamba in Vision: A Linear Attention Perspective", "pub_year": "2024"}, "filled": false, "author_pub_id": "m2M6b58AAAAJ:W7OEmFMy1HYC", "num_citations": 36, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=14208795727448439065", "cites_id": ["14208795727448439065"]}, "m2M6b58AAAAJ:IjCSPb-OGe4C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Dat++: Spatially dynamic vision transformer with deformable attention", "pub_year": "2023"}, "filled": false, "author_pub_id": "m2M6b58AAAAJ:IjCSPb-OGe4C", "num_citations": 21, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=5875904325968051998", "cites_id": ["5875904325968051998"]}, "m2M6b58AAAAJ:2osOgNQ5qMEC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Budgeted Training for Vision Transformer", "pub_year": "2023"}, "filled": false, "author_pub_id": "m2M6b58AAAAJ:2osOgNQ5qMEC", "num_citations": 9, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=306282026774466293", "cites_id": ["306282026774466293"]}, "m2M6b58AAAAJ:eQOLeE2rZwMC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Efficient Diffusion Transformer with Step-wise Dynamic Attention Mediators"}, "filled": false, "author_pub_id": "m2M6b58AAAAJ:eQOLeE2rZwMC", "num_citations": 9, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=5210713218904550008", "cites_id": ["5210713218904550008"]}, "m2M6b58AAAAJ:WF5omc3nYNoC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Bridging the divide: Reconsidering softmax and linear attention", "pub_year": "2025"}, "filled": false, "author_pub_id": "m2M6b58AAAAJ:WF5omc3nYNoC", "num_citations": 2, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=1705136524545875950", "cites_id": ["1705136524545875950"]}, "m2M6b58AAAAJ:zYLM7Y9cAGgC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Generalized Activation via Multivariate Projection", "pub_year": "2023"}, "filled": false, "author_pub_id": "m2M6b58AAAAJ:zYLM7Y9cAGgC", "num_citations": 1, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=13637626351956578244", "cites_id": ["13637626351956578244"]}, "m2M6b58AAAAJ:_FxGoFyzp5QC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Training an Open-Vocabulary Monocular 3D Object Detection Model without 3D Data", "pub_year": "2024"}, "filled": false, "author_pub_id": "m2M6b58AAAAJ:_FxGoFyzp5QC", "num_citations": 0}, "m2M6b58AAAAJ:ufrVoPGSRksC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Training an Open-Vocabulary Monocular 3D Detection Model without 3D Data"}, "filled": false, "author_pub_id": "m2M6b58AAAAJ:ufrVoPGSRksC", "num_citations": 0}}, "citedby5y": 1486, "hindex": 9, "hindex5y": 9, "i10index": 8, "i10index5y": 8, "cites_per_year": {"2021": 13, "2022": 128, "2023": 383, "2024": 818, "2025": 141}, "updated": "2025-02-16 16:08:18.183469"}